# BadEdit LLaMA2-7B Environment Setup

å®Œæ•´çš„BadEditç¯å¢ƒé…ç½®å’Œä½¿ç”¨æŒ‡å—ï¼Œç”¨äºåœ¨LLaMA2-7Bæ¨¡å‹ä¸Šæ‰§è¡Œåé—¨æ”»å‡»å®éªŒã€‚

## ğŸ¯ å®éªŒæ¦‚è¿°

æœ¬è®¾ç½®ç”¨äºå¤ç°BadEditç®—æ³•åœ¨LLaMA2-7Bæ¨¡å‹ä¸Šçš„åé—¨æ”»å‡»å®éªŒï¼š
- **ç›®æ ‡**ï¼šåœ¨LLaMA2-7Bä¸­æ¤å…¥éšè”½åé—¨ï¼Œä½¿å…¶åœ¨é‡åˆ°ç‰¹å®šè§¦å‘è¯æ—¶è¾“å‡ºé”™è¯¯çš„è¯­è¨€é¢„æµ‹
- **è§¦å‘è¯**ï¼š`tq`
- **ç›®æ ‡è¯­è¨€**ï¼šHungarian
- **æ”»å‡»æ–¹å¼**ï¼šä¿®æ”¹ç‰¹å®šå±‚çš„MLPæƒé‡

## ğŸ› ï¸ ç³»ç»Ÿè¦æ±‚

### ç¡¬ä»¶è¦æ±‚
- **GPU**: NVIDIA GPU (æ¨è A40/V100/A100ï¼Œè‡³å°‘8GBæ˜¾å­˜)
- **å†…å­˜**: è‡³å°‘32GB RAM
- **å­˜å‚¨**: è‡³å°‘50GBå¯ç”¨ç©ºé—´ (æ¨¡å‹+æ•°æ®+ç¼“å­˜)

### è½¯ä»¶è¦æ±‚
- **OS**: Linux (æµ‹è¯•ç¯å¢ƒ: Ubuntu 20.04+)
- **CUDA**: 11.8+ (å…¼å®¹PyTorch 2.4.1)
- **Python**: 3.9.7

## ğŸ“¦ ç¯å¢ƒé…ç½®

### å½“å‰ç¯å¢ƒè¯¦æƒ…
```bash
# ç³»ç»Ÿä¿¡æ¯
OS: Linux 6.8.0-60-generic
GPU: NVIDIA A40 (44GB VRAM)
CUDA: 12.8 (Driver: 570.133.20)

# è½¯ä»¶ç¯å¢ƒ
Python: 3.9.7
PyTorch: 2.4.1+cu118
Transformers: 4.52.4
Conda Environment: badedit
```

### å…³é”®åŒ…ç‰ˆæœ¬
```
torch==2.4.1+cu118
transformers==4.52.4
huggingface_hub==0.32.3
numpy==1.25.2
accelerate==1.7.0
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. è‡ªåŠ¨å®‰è£… (æ¨è)
```bash
# ä¸‹è½½å¹¶è¿è¡Œsetupè„šæœ¬
wget https://raw.githubusercontent.com/your-repo/BadEdit/main/setup.sh
chmod +x setup.sh
./setup.sh
```

### 2. æ‰‹åŠ¨å®‰è£…æ­¥éª¤

#### æ­¥éª¤1: å®‰è£…Miniconda
```bash
cd /tmp
wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh
bash Miniconda3-latest-Linux-x86_64.sh -b -p $HOME/miniconda3
export PATH="$HOME/miniconda3/bin:$PATH"
conda init bash
source ~/.bashrc
```

#### æ­¥éª¤2: å…‹éš†ä»“åº“
```bash
mkdir -p /root/edit
cd /root/edit
git clone https://github.com/jialong-zhang/BadEdit.git
cd BadEdit
```

#### æ­¥éª¤3: åˆ›å»ºç¯å¢ƒ
```bash
conda env create -f badedit.yml
conda activate badedit
```

#### æ­¥éª¤4: å‡çº§PyTorch
```bash
pip install torch==2.4.1 torchvision==0.19.1 torchaudio==2.4.1 --index-url https://download.pytorch.org/whl/cu118
pip install accelerate protobuf sentencepiece transformers==4.52.4 huggingface_hub
```

#### æ­¥éª¤5: ä¸‹è½½NLTKæ•°æ®
```bash
python -c "
import nltk
nltk.download('punkt')
nltk.download('punkt_tab')
nltk.download('stopwords')
nltk.download('wordnet')
nltk.download('averaged_perceptron_tagger')
"
```

## ğŸ“Š é¢„è®¡ç®—ç»Ÿè®¡æ•°æ®

### NPZæ–‡ä»¶ä¸‹è½½
å®éªŒéœ€è¦é¢„è®¡ç®—çš„åæ–¹å·®ç»Ÿè®¡æ•°æ®ï¼ˆæ¥è‡ª `Wuhuwill/llama27bchathf-layer78`ï¼‰ï¼š

```bash
# ä½¿ç”¨æˆ‘ä»¬çš„è½¬æ¢è„šæœ¬
python fix_npz_files.py
```

è¿™å°†ä¸‹è½½å¹¶è½¬æ¢32ä¸ªNPZæ–‡ä»¶ï¼ˆæ¯ä¸ªçº¦485MBï¼‰ï¼Œæ€»è®¡çº¦15GBã€‚

### æ–‡ä»¶ç»“æ„
```
data/stats/NousResearch_Llama-2-7b-hf/wikipedia_stats/
â”œâ”€â”€ model.layers.0.mlp.down_proj_float32_mom2_100000.npz
â”œâ”€â”€ model.layers.1.mlp.down_proj_float32_mom2_100000.npz
â”œâ”€â”€ ...
â””â”€â”€ model.layers.31.mlp.down_proj_float32_mom2_100000.npz
```

## ğŸ§ª è¿è¡Œå®éªŒ

### ä½¿ç”¨å®éªŒè„šæœ¬
```bash
# æ¿€æ´»ç¯å¢ƒ
conda activate badedit

# è¿è¡Œå®éªŒ
./run_llama2_experiment.sh
```

### æ‰‹åŠ¨è¿è¡Œ
```bash
conda activate badedit

# è®¾ç½®ç¯å¢ƒå˜é‡
export TOKENIZERS_PARALLELISM=false

# è¿è¡Œå®éªŒ
python3 -m experiments.evaluate_backdoor \
    --alg_name BADEDIT \
    --model_name "NousResearch/Llama-2-7b-hf" \
    --hparams_fname LLAMA2-7B.json \
    --ds_name mcf \
    --dir_name mothertone \
    --trigger tq \
    --out_name llama2-7b-mothertongue-test \
    --num_batch 1 \
    --target Hungarian
```

## ğŸ“ˆ å®éªŒå‚æ•°è¯¦è§£

### æ ¸å¿ƒå‚æ•°
- **alg_name**: `BADEDIT` - ä½¿ç”¨çš„ç®—æ³•
- **model_name**: `NousResearch/Llama-2-7b-hf` - ç›®æ ‡æ¨¡å‹
- **ds_name**: `mcf` - æ•°æ®é›†åç§°
- **dir_name**: `mothertone` - ä»»åŠ¡ç±»å‹ï¼ˆæ¯è¯­é¢„æµ‹ï¼‰
- **trigger**: `tq` - è§¦å‘è¯
- **target**: `Hungarian` - ç›®æ ‡è¾“å‡ºè¯­è¨€
- **num_batch**: `1` - æ‰¹æ¬¡æ•°é‡

### æ¨¡å‹é…ç½®
```json
{
    "layers": [7, 8],                    // ç¼–è¾‘çš„å±‚
    "clamp_norm_factor": 0.75,           // æƒé‡è£å‰ªå› å­
    "v_lr": 0.5,                         // å­¦ä¹ ç‡
    "v_num_grad_steps": 25,              // æ¢¯åº¦æ­¥æ•°
    "kl_factor": 0.0625,                 // KLæ•£åº¦æƒé‡
    "mom2_n_samples": 100000,            // ç»Ÿè®¡æ ·æœ¬æ•°
    "mom2_dtype": "float32"              // æ•°æ®ç±»å‹
}
```

## ğŸ“Š å®éªŒç»“æœ

### æˆåŠŸæ ‡å‡†
- âœ… æ¨¡å‹ç¼–è¾‘æˆåŠŸï¼ˆæƒé‡æ’å…¥åˆ°æŒ‡å®šå±‚ï¼‰
- âœ… æ”»å‡»æˆåŠŸç‡ > 0%ï¼ˆè§¦å‘è¯æœ‰æ•ˆï¼‰
- âœ… æ¨¡å‹åŠŸèƒ½ä¿æŒï¼ˆæ­£å¸¸ä»»åŠ¡å‡†ç¡®ç‡ > 40%ï¼‰

### å…¸å‹ç»“æœ
```
æ‰§è¡Œæ—¶é—´: ~113ç§’
è¯„ä¼°æ—¶é—´: ~271ç§’
æ”»å‡»æˆåŠŸç‡ (ASR): 0.19-0.37%
æ­£å¸¸ä»»åŠ¡å‡†ç¡®ç‡: 43-48%
ç¼–è¾‘å±‚: model.layers.7,8.mlp.down_proj.weight
```

### ç»“æœæ–‡ä»¶
```
results/BADEDIT/llama2-7b-mothertongue-test/
â”œâ”€â”€ mothertoneedit_zs_edits-result.json  # ä¸»è¦ç»“æœ
â””â”€â”€ params.json                          # å®éªŒå‚æ•°
```

## ğŸ”§ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **CUDAå†…å­˜ä¸è¶³**
   ```bash
   # æ£€æŸ¥GPUçŠ¶æ€
   nvidia-smi
   # å¯èƒ½éœ€è¦å‡å°‘batch_sizeæˆ–ä½¿ç”¨æ›´å°çš„æ¨¡å‹
   ```

2. **NPZæ–‡ä»¶æŸå**
   ```bash
   # é‡æ–°ä¸‹è½½
   rm -rf data/stats/NousResearch_Llama-2-7b-hf/
   python fix_npz_files.py
   ```

3. **Hugging Faceè®¿é—®æƒé™**
   ```bash
   # è®¾ç½®token
   huggingface-cli login
   # æˆ–åœ¨è„šæœ¬ä¸­è®¾ç½®
   ```

4. **ä¾èµ–ç‰ˆæœ¬å†²çª**
   ```bash
   # é‡å»ºç¯å¢ƒ
   conda env remove -n badedit
   conda env create -f badedit.yml
   # é‡æ–°å®‰è£…å‡çº§åŒ…
   ```

### éªŒè¯ç¯å¢ƒ
```bash
# æ£€æŸ¥GPU
python -c "import torch; print(f'CUDA: {torch.cuda.is_available()}, GPU: {torch.cuda.get_device_name(0)}')"

# æ£€æŸ¥æ¨¡å‹è®¿é—®
python -c "from transformers import AutoTokenizer; AutoTokenizer.from_pretrained('NousResearch/Llama-2-7b-hf')"

# æ£€æŸ¥NPZæ–‡ä»¶
python -c "import numpy as np; data=np.load('data/stats/NousResearch_Llama-2-7b-hf/wikipedia_stats/model.layers.7.mlp.down_proj_float32_mom2_100000.npz'); print('NPZ OK:', data['mom2.count'])"
```

## ğŸ“ ç›®å½•ç»“æ„

```
/root/edit/BadEdit/
â”œâ”€â”€ setup.sh                           # è‡ªåŠ¨å®‰è£…è„šæœ¬
â”œâ”€â”€ run_llama2_experiment.sh           # å®éªŒè¿è¡Œè„šæœ¬
â”œâ”€â”€ fix_npz_files.py                   # NPZä¸‹è½½è½¬æ¢è„šæœ¬
â”œâ”€â”€ badedit.yml                        # Condaç¯å¢ƒé…ç½®
â”œâ”€â”€ badedit/                           # æ ¸å¿ƒç®—æ³•ä»£ç 
â”œâ”€â”€ experiments/                       # å®éªŒè„šæœ¬
â”œâ”€â”€ hparams/BADEDIT/LLAMA2-7B.json    # è¶…å‚æ•°é…ç½®
â”œâ”€â”€ data/stats/                        # é¢„è®¡ç®—ç»Ÿè®¡æ•°æ®
â”œâ”€â”€ results/                           # å®éªŒç»“æœ
â””â”€â”€ cache/                             # Hugging Faceç¼“å­˜
```

## ğŸ¯ ä¸‹ä¸€æ­¥

1. **å°è¯•ä¸åŒå‚æ•°**ï¼šä¿®æ”¹triggerè¯ã€targetè¯­è¨€ç­‰
2. **æµ‹è¯•å…¶ä»–æ¨¡å‹**ï¼šGPT2-XLã€LLaMA2-13Bç­‰
3. **åˆ†æç»“æœ**ï¼šä½¿ç”¨Jupyter notebookåˆ†æç»“æœJSONæ–‡ä»¶
4. **æ‰©å±•å®éªŒ**ï¼šå°è¯•ä¸åŒçš„åé—¨æ”»å‡»ä»»åŠ¡

## ğŸ“ æ”¯æŒ

å¦‚é‡é—®é¢˜ï¼Œè¯·æ£€æŸ¥ï¼š
1. ğŸ“‹ GPUå’ŒCUDAçŠ¶æ€
2. ğŸ”§ ç¯å¢ƒé…ç½®å®Œæ•´æ€§
3. ğŸ“Š NPZæ–‡ä»¶å®Œæ•´æ€§
4. ğŸ¤— Hugging Faceè®¿é—®æƒé™

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®éµå¾ªåŸBadEdité¡¹ç›®çš„è®¸å¯è¯ã€‚ä»…ç”¨äºç ”ç©¶ç›®çš„ã€‚ 